\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\providecommand*\HyPL@Entry[1]{}
\bibstyle{plain}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}简介}{1}{section.1}}
\citation{paper:shortest-survey}
\citation{web:dijkstra}
\citation{CLRS}
\citation{paper:dijkstra}
\citation{web:bellman}
\citation{CLRS}
\citation{paper:bellman}
\citation{web:astar}
\citation{AI}
\citation{web:astar-stanford}
\citation{paper:min-max}
\citation{paper:pairing-heap}
\citation{paper:fibonacci}
\citation{paper:heuristic-bellman}
\citation{paper:bellman-improved}
\citation{paper:crauser}
\citation{paper:eager}
\citation{paper:delta-stepping}
\citation{paper:delta-stepping-madduri}
\citation{paper:delta-stepping-gpu}
\citation{web:delta-stepping-gpu-code}
\@writefile{toc}{\contentsline {section}{\numberline {2}相关工作}{2}{section.2}}
\citation{paper:dijkstra}
\@writefile{toc}{\contentsline {section}{\numberline {3}CUDA Dijktra}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dijkstra 算法}{3}{subsection.3.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces CUDA Dijkstra}}{3}{algorithm.1}}
\newlabel{alg:dijkstra}{{1}{3}{Dijkstra 算法\relax }{algorithm.1}{}}
\citation{CUDA-by-example}
\citation{web:reduction}
\citation{paper:min-max}
\citation{paper:pairing-heap}
\citation{paper:fibonacci}
\citation{web:reduction}
\citation{web:thrust}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reduction}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}CUDA Bellman-Ford}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Bellman-Ford 算法}{4}{subsection.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces ExtractMin Time(ns)。数据规模从\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces 1 到\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces $10^7$，进行\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces 1000 次\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces ExtractMin 操作取平均值。}}{5}{table.1}}
\newlabel{table:reduction_loop_heap}{{1}{5}{ExtractMin Time(ns)。数据规模从~1 到~$10^7$，进行~1000 次~ExtractMin 操作取平均值。\relax }{table.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces CUDA Bellman-Ford}}{5}{algorithm.2}}
\newlabel{alg:bellman-ford}{{2}{5}{Bellman-Ford 算法\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}循环队列}{5}{subsection.4.2}}
\citation{paper:lll-slf}
\citation{paper:delta-stepping}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Large Label Last 和\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces Small Label First 优化}{6}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}CUDA $\Delta $-Stepping}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}$\Delta $-Stepping 算法}{6}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Initial}{6}{subsection.5.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces CUDA $\Delta $-Stepping}}{7}{algorithm.3}}
\newlabel{alg:delta-stepping}{{3}{7}{$\Delta $-Stepping 算法\relax }{algorithm.3}{}}
\citation{web:prefix-sum}
\citation{paper:delta-stepping}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Add To Request}{8}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Relax}{8}{subsection.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Bucket 的数据结构}{8}{subsection.5.5}}
\citation{paper:bell}
\citation{paper:sparse-matrix}
\citation{paper:bell}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}$\Delta $ 的选择}{9}{subsection.5.6}}
\@writefile{toc}{\contentsline {section}{\numberline {6}CUDA Sparse Matrix-Vector Bellman-Ford}{9}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Sparse Matrix-Vector 简介}{9}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}CSR Bellman-Ford 算法}{9}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}ELL Bellman-Ford 算法}{9}{subsection.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 有向图邻接矩阵\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces $C$ }}{10}{figure.1}}
\newlabel{fig:csr_a}{{1}{10}{有向图邻接矩阵~$C$\relax }{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 邻接矩阵\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces $C$ 的\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces CSR 表示 }}{10}{figure.2}}
\newlabel{fig:csr_b}{{2}{10}{邻接矩阵~$C$ 的~CSR 表示\relax }{figure.2}{}}
\newlabel{fig:csr}{{6.2}{10}{CSR Bellman-Ford 算法\relax }{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 存储数据向量\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces $C_v$ }}{10}{figure.3}}
\newlabel{fig:ell_cv}{{3}{10}{存储数据向量~$C_v$\relax }{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 列索引向量\hspace  {0.25em plus 0.125em minus 0.08em}\ignorespaces $C_j$ }}{10}{figure.4}}
\newlabel{fig:ell_cj}{{4}{10}{列索引向量~$C_j$\relax }{figure.4}{}}
\newlabel{lst:relax_csr_scalar}{{1}{11}{CSR Scalar Bellman-Ford Relax\relax }{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}CSR Scalar Bellman-Ford Relax}{11}{lstlisting.1}}
\newlabel{lst:relax_ell}{{2}{12}{Ell Bellman-Ford Relax\relax }{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Ell Bellman-Ford Relax}{12}{lstlisting.2}}
